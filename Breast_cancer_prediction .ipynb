{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     diagnosis  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "..         ...  \n",
       "564          0  \n",
       "565          0  \n",
       "566          0  \n",
       "567          0  \n",
       "568          1  \n",
       "\n",
       "[569 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing libraries to read the dataset and plotting to analyze the data\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('Breast_cancer_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-ee06883b3735>:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X,Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19196264 0.1247173  0.28878098 0.28726886 0.10727022]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1de8a2366a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Feature engineering by checking scores of each paarmeter in training the dataset\n",
    "X = df[['mean_radius','mean_texture','mean_perimeter','mean_area','mean_smoothness']]\n",
    "Y = df[['diagnosis']]\n",
    "model = RandomForestClassifier(n_estimators=340)\n",
    "model.fit(X,Y)\n",
    "feature_importances = model.feature_importances_\n",
    "print(feature_importances)\n",
    "importance_df = pd.DataFrame({\"Features\":pd.DataFrame(X).columns,\"Importances\":feature_importances})\n",
    "importance_df.set_index(\"Importances\")\n",
    "importance_df = importance_df.sort_values(\"Importances\")\n",
    "importance_df.plot.bar(color=\"teal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 3) (171, 3)\n",
      "(398, 1) (171, 1)\n"
     ]
    }
   ],
   "source": [
    "#now let us split the data for training and testing purposes\n",
    "x_new = df[['mean_radius','mean_perimeter','mean_area']]\n",
    "y_new = df[['diagnosis']]\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_new,y_new,random_state=42,test_size=0.3)\n",
    "print(x_train.shape,x_test.shape)\n",
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9239766081871345\n"
     ]
    }
   ],
   "source": [
    "#Fit the model and predicting the output using Logistic Regression\n",
    "linear = LogisticRegression()\n",
    "linear.fit(x_train,y_train)\n",
    "y_pred = linear.predict(x_test)\n",
    "score = accuracy_score(y_test,y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model using RandomForestClassifier, first we need to do featurte scaling\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-df3ae2369d10>:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier.fit(x_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9239766081871345\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=85, random_state=0)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "score = accuracy_score(y_test,y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "13/13 [==============================] - 1s 3ms/step - loss: 0.5901 - accuracy: 0.8357\n",
      "Epoch 2/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.8792\n",
      "Epoch 3/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3484 - accuracy: 0.8725\n",
      "Epoch 4/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3257 - accuracy: 0.8474\n",
      "Epoch 5/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2894 - accuracy: 0.8856\n",
      "Epoch 6/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2432 - accuracy: 0.8933\n",
      "Epoch 7/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2797 - accuracy: 0.8735\n",
      "Epoch 8/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2922 - accuracy: 0.8832\n",
      "Epoch 9/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2936 - accuracy: 0.8742\n",
      "Epoch 10/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3346 - accuracy: 0.8421\n",
      "Epoch 11/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2712 - accuracy: 0.8868\n",
      "Epoch 12/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3019 - accuracy: 0.8801\n",
      "Epoch 13/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3045 - accuracy: 0.8623\n",
      "Epoch 14/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2753 - accuracy: 0.8916\n",
      "Epoch 15/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3103 - accuracy: 0.8673\n",
      "Epoch 16/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.8620\n",
      "Epoch 17/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2972 - accuracy: 0.8804\n",
      "Epoch 18/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2795 - accuracy: 0.8745\n",
      "Epoch 19/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2974 - accuracy: 0.8758\n",
      "Epoch 20/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3020 - accuracy: 0.8694\n",
      "Epoch 21/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2773 - accuracy: 0.8859\n",
      "Epoch 22/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2932 - accuracy: 0.8774\n",
      "Epoch 23/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8679\n",
      "Epoch 24/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2826 - accuracy: 0.8721\n",
      "Epoch 25/256\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2950 - accuracy: 0.8674\n",
      "Epoch 26/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.8720\n",
      "Epoch 27/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2886 - accuracy: 0.8694\n",
      "Epoch 28/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2482 - accuracy: 0.8873\n",
      "Epoch 29/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.9011\n",
      "Epoch 30/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8693\n",
      "Epoch 31/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2715 - accuracy: 0.8896\n",
      "Epoch 32/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.8710\n",
      "Epoch 33/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.9036\n",
      "Epoch 34/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.8616\n",
      "Epoch 35/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2905 - accuracy: 0.8774\n",
      "Epoch 36/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2843 - accuracy: 0.8811\n",
      "Epoch 37/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8659\n",
      "Epoch 38/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2957 - accuracy: 0.8740\n",
      "Epoch 39/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2678 - accuracy: 0.8879\n",
      "Epoch 40/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2730 - accuracy: 0.8823\n",
      "Epoch 41/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2518 - accuracy: 0.8985\n",
      "Epoch 42/256\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3036 - accuracy: 0.8645\n",
      "Epoch 43/256\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2798 - accuracy: 0.8726\n",
      "Epoch 44/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2807 - accuracy: 0.8805\n",
      "Epoch 45/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.9053\n",
      "Epoch 46/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2792 - accuracy: 0.8787\n",
      "Epoch 47/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.8924\n",
      "Epoch 48/256\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2510 - accuracy: 0.8839\n",
      "Epoch 49/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2800 - accuracy: 0.8721\n",
      "Epoch 50/256\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2794 - accuracy: 0.8680\n",
      "Epoch 51/256\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3032 - accuracy: 0.81 - 0s 2ms/step - loss: 0.2745 - accuracy: 0.8660\n",
      "Epoch 52/256\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2443 - accuracy: 0.9010\n",
      "Epoch 53/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2671 - accuracy: 0.8657\n",
      "Epoch 54/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.8957\n",
      "Epoch 55/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.8787\n",
      "Epoch 56/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.8718\n",
      "Epoch 57/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2400 - accuracy: 0.8899\n",
      "Epoch 58/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2358 - accuracy: 0.8907\n",
      "Epoch 59/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2516 - accuracy: 0.8819\n",
      "Epoch 60/256\n",
      "13/13 [==============================] - 0s 917us/step - loss: 0.2688 - accuracy: 0.8667\n",
      "Epoch 61/256\n",
      "13/13 [==============================] - 0s 810us/step - loss: 0.2374 - accuracy: 0.8917\n",
      "Epoch 62/256\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.8779\n",
      "Epoch 63/256\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.8867\n",
      "Epoch 64/256\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2517 - accuracy: 0.8835\n",
      "Epoch 65/256\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2494 - accuracy: 0.8842\n",
      "Epoch 66/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2822 - accuracy: 0.8609\n",
      "Epoch 67/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2407 - accuracy: 0.8891\n",
      "Epoch 68/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2333 - accuracy: 0.8928\n",
      "Epoch 69/256\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2387 - accuracy: 0.8972\n",
      "Epoch 70/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2789 - accuracy: 0.8697\n",
      "Epoch 71/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2305 - accuracy: 0.9052\n",
      "Epoch 72/256\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2541 - accuracy: 0.8955\n",
      "Epoch 73/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.8795\n",
      "Epoch 74/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2377 - accuracy: 0.8911\n",
      "Epoch 75/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2402 - accuracy: 0.9021\n",
      "Epoch 76/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2076 - accuracy: 0.9123\n",
      "Epoch 77/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2237 - accuracy: 0.9130\n",
      "Epoch 78/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.8696\n",
      "Epoch 79/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.8883\n",
      "Epoch 80/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.8949\n",
      "Epoch 81/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2551 - accuracy: 0.8970\n",
      "Epoch 82/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2112 - accuracy: 0.9016\n",
      "Epoch 83/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9149\n",
      "Epoch 84/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2305 - accuracy: 0.8988\n",
      "Epoch 85/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2808 - accuracy: 0.8780\n",
      "Epoch 86/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2158 - accuracy: 0.9070\n",
      "Epoch 87/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2135 - accuracy: 0.9058\n",
      "Epoch 88/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.8996\n",
      "Epoch 89/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2241 - accuracy: 0.8971\n",
      "Epoch 90/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2539 - accuracy: 0.8930\n",
      "Epoch 91/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2397 - accuracy: 0.8977\n",
      "Epoch 92/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.9022\n",
      "Epoch 93/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2294 - accuracy: 0.9033\n",
      "Epoch 94/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2421 - accuracy: 0.9007\n",
      "Epoch 95/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2643 - accuracy: 0.8877\n",
      "Epoch 96/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2530 - accuracy: 0.8981\n",
      "Epoch 97/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2563 - accuracy: 0.8929\n",
      "Epoch 98/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2269 - accuracy: 0.9088\n",
      "Epoch 99/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2348 - accuracy: 0.9037\n",
      "Epoch 100/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2408 - accuracy: 0.9014\n",
      "Epoch 101/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2371 - accuracy: 0.8916\n",
      "Epoch 102/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2107 - accuracy: 0.9170\n",
      "Epoch 103/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2579 - accuracy: 0.9024\n",
      "Epoch 104/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2261 - accuracy: 0.9081\n",
      "Epoch 105/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2269 - accuracy: 0.9132\n",
      "Epoch 106/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.9016\n",
      "Epoch 107/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.9173\n",
      "Epoch 108/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1968 - accuracy: 0.9162\n",
      "Epoch 109/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2287 - accuracy: 0.9049\n",
      "Epoch 110/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2474 - accuracy: 0.8932\n",
      "Epoch 111/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9100\n",
      "Epoch 112/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2342 - accuracy: 0.9096\n",
      "Epoch 113/256\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.2412 - accuracy: 0.9044\n",
      "Epoch 114/256\n",
      "13/13 [==============================] - 0s 831us/step - loss: 0.2329 - accuracy: 0.9038\n",
      "Epoch 115/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2316 - accuracy: 0.9026\n",
      "Epoch 116/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8917\n",
      "Epoch 117/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2373 - accuracy: 0.9029\n",
      "Epoch 118/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.9001\n",
      "Epoch 119/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1901 - accuracy: 0.9351\n",
      "Epoch 120/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9272\n",
      "Epoch 121/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2151 - accuracy: 0.9133\n",
      "Epoch 122/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2295 - accuracy: 0.9074\n",
      "Epoch 123/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2125 - accuracy: 0.9158\n",
      "Epoch 124/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.9173\n",
      "Epoch 125/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2300 - accuracy: 0.9026\n",
      "Epoch 126/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.8978\n",
      "Epoch 127/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2426 - accuracy: 0.8899\n",
      "Epoch 128/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.8995\n",
      "Epoch 129/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.9070\n",
      "Epoch 130/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2640 - accuracy: 0.8850\n",
      "Epoch 131/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2150 - accuracy: 0.9138\n",
      "Epoch 132/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2556 - accuracy: 0.8901\n",
      "Epoch 133/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2554 - accuracy: 0.8938\n",
      "Epoch 134/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2160 - accuracy: 0.9226\n",
      "Epoch 135/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2298 - accuracy: 0.9021\n",
      "Epoch 136/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.8889\n",
      "Epoch 137/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 0.8978\n",
      "Epoch 138/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2482 - accuracy: 0.8992\n",
      "Epoch 139/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2052 - accuracy: 0.9092\n",
      "Epoch 140/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2296 - accuracy: 0.9195\n",
      "Epoch 141/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2173 - accuracy: 0.9162\n",
      "Epoch 142/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2385 - accuracy: 0.9179\n",
      "Epoch 143/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.9223\n",
      "Epoch 144/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2131 - accuracy: 0.9208\n",
      "Epoch 145/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2350 - accuracy: 0.9080\n",
      "Epoch 146/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2038 - accuracy: 0.9240\n",
      "Epoch 147/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2173 - accuracy: 0.9173\n",
      "Epoch 148/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 0.9153\n",
      "Epoch 149/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2054 - accuracy: 0.9148\n",
      "Epoch 150/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2759 - accuracy: 0.8811\n",
      "Epoch 151/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2244 - accuracy: 0.9164\n",
      "Epoch 152/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.9359\n",
      "Epoch 153/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2532 - accuracy: 0.8938\n",
      "Epoch 154/256\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2158 - accuracy: 0.9114\n",
      "Epoch 155/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2363 - accuracy: 0.9179\n",
      "Epoch 156/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.9158\n",
      "Epoch 157/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9170\n",
      "Epoch 158/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.9201\n",
      "Epoch 159/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2150 - accuracy: 0.9138\n",
      "Epoch 160/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2024 - accuracy: 0.9187\n",
      "Epoch 161/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2371 - accuracy: 0.9151\n",
      "Epoch 162/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2051 - accuracy: 0.9305\n",
      "Epoch 163/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2700 - accuracy: 0.8762\n",
      "Epoch 164/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2055 - accuracy: 0.9217\n",
      "Epoch 165/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1877 - accuracy: 0.9230\n",
      "Epoch 166/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9114\n",
      "Epoch 167/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2215 - accuracy: 0.9105\n",
      "Epoch 168/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2155 - accuracy: 0.9120\n",
      "Epoch 169/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.9109\n",
      "Epoch 170/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.9014\n",
      "Epoch 171/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.9090\n",
      "Epoch 172/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2245 - accuracy: 0.9060\n",
      "Epoch 173/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2073 - accuracy: 0.9214\n",
      "Epoch 174/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9071\n",
      "Epoch 175/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.9113\n",
      "Epoch 176/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2209 - accuracy: 0.9036\n",
      "Epoch 177/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.9103\n",
      "Epoch 178/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2054 - accuracy: 0.9136\n",
      "Epoch 179/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2205 - accuracy: 0.9107\n",
      "Epoch 180/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2397 - accuracy: 0.8945\n",
      "Epoch 181/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2092 - accuracy: 0.9182\n",
      "Epoch 182/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9102\n",
      "Epoch 183/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2247 - accuracy: 0.9058\n",
      "Epoch 184/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.9272\n",
      "Epoch 185/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.9239\n",
      "Epoch 186/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.9140\n",
      "Epoch 187/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2174 - accuracy: 0.9119\n",
      "Epoch 188/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.9251\n",
      "Epoch 189/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2375 - accuracy: 0.9118\n",
      "Epoch 190/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2127 - accuracy: 0.9200\n",
      "Epoch 191/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9110\n",
      "Epoch 192/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2097 - accuracy: 0.9148\n",
      "Epoch 193/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2399 - accuracy: 0.9102\n",
      "Epoch 194/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.9086\n",
      "Epoch 195/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2254 - accuracy: 0.9028\n",
      "Epoch 196/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.8873\n",
      "Epoch 197/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.9092\n",
      "Epoch 198/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2204 - accuracy: 0.9121\n",
      "Epoch 199/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2018 - accuracy: 0.9271\n",
      "Epoch 200/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 0.8992\n",
      "Epoch 201/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2196 - accuracy: 0.9175\n",
      "Epoch 202/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.9010\n",
      "Epoch 203/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2204 - accuracy: 0.9089\n",
      "Epoch 204/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9129\n",
      "Epoch 205/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 0.9354\n",
      "Epoch 206/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.8914\n",
      "Epoch 207/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.8959\n",
      "Epoch 208/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2551 - accuracy: 0.9027\n",
      "Epoch 209/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2233 - accuracy: 0.9156\n",
      "Epoch 210/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.9029\n",
      "Epoch 211/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.9068\n",
      "Epoch 212/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.9104\n",
      "Epoch 213/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2321 - accuracy: 0.8980\n",
      "Epoch 214/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2230 - accuracy: 0.9139\n",
      "Epoch 215/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1895 - accuracy: 0.9289\n",
      "Epoch 216/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.9307\n",
      "Epoch 217/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.8908\n",
      "Epoch 218/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.9148\n",
      "Epoch 219/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.9271\n",
      "Epoch 220/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2194 - accuracy: 0.9085\n",
      "Epoch 221/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.9014\n",
      "Epoch 222/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2161 - accuracy: 0.9225\n",
      "Epoch 223/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2017 - accuracy: 0.9200\n",
      "Epoch 224/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2382 - accuracy: 0.8930\n",
      "Epoch 225/256\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2142 - accuracy: 0.9090\n",
      "Epoch 226/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.9020\n",
      "Epoch 227/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.9287\n",
      "Epoch 228/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9137\n",
      "Epoch 229/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2402 - accuracy: 0.9066\n",
      "Epoch 230/256\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2292 - accuracy: 0.9168\n",
      "Epoch 231/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2247 - accuracy: 0.9112\n",
      "Epoch 232/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.9230\n",
      "Epoch 233/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1996 - accuracy: 0.9264\n",
      "Epoch 234/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 0.9208\n",
      "Epoch 235/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2213 - accuracy: 0.9070\n",
      "Epoch 236/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1951 - accuracy: 0.9263\n",
      "Epoch 237/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2437 - accuracy: 0.8997\n",
      "Epoch 238/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2261 - accuracy: 0.8835\n",
      "Epoch 239/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 0.8934\n",
      "Epoch 240/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2419 - accuracy: 0.8904\n",
      "Epoch 241/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.9327\n",
      "Epoch 242/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2316 - accuracy: 0.9062\n",
      "Epoch 243/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.9199\n",
      "Epoch 244/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2295 - accuracy: 0.9023\n",
      "Epoch 245/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2217 - accuracy: 0.9053\n",
      "Epoch 246/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.9268\n",
      "Epoch 247/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1996 - accuracy: 0.9126\n",
      "Epoch 248/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2193 - accuracy: 0.9176\n",
      "Epoch 249/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2009 - accuracy: 0.9146\n",
      "Epoch 250/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2112 - accuracy: 0.8908\n",
      "Epoch 251/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2072 - accuracy: 0.9188\n",
      "Epoch 252/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2064 - accuracy: 0.9090\n",
      "Epoch 253/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2330 - accuracy: 0.8926\n",
      "Epoch 254/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2325 - accuracy: 0.8902\n",
      "Epoch 255/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1729 - accuracy: 0.9330\n",
      "Epoch 256/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2158 - accuracy: 0.9137\n"
     ]
    }
   ],
   "source": [
    "#Using Neural Networks to train the data\n",
    "model = Sequential([Dense(64, activation='relu',input_shape=(3,)),    \n",
    "                    Dense(64, activation='relu'),\n",
    "                    Dense(1, activation='sigmoid'),])\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(x_train,y_train,batch_size=32, epochs=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1560 - accuracy: 0.9415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1560411900281906, 0.9415204524993896]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_radius = 14.05\n",
    "mean_perimeter = 91.38\n",
    "mean_area = 600.4\n",
    "new_data = np.array([[mean_radius, mean_perimeter, mean_area]])\n",
    "prediction = model.predict(new_data)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally at: http://127.0.0.1:7860/\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7860/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1de8dd1b490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Flask 'gradio.networking'>, 'http://127.0.0.1:7860/', None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def predictions(mean_radius, mean_perimeter, mean_area):\n",
    "    new_data = np.array([[mean_radius, mean_perimeter, mean_area]])\n",
    "    prediction = linear.predict(new_data)\n",
    "    if prediction[0] == 0:\n",
    "        return \"Negative ðŸŽ‰\"\n",
    "    else:\n",
    "        return \"Positive ðŸ˜ž\"\n",
    "\n",
    "def something(hello):\n",
    "    print(\"Hello\" + hello)\n",
    "\n",
    "iface = gr.Interface(\n",
    "  fn=predictions,\n",
    "  inputs=[\"number\", \"number\", \"number\"],\n",
    "  outputs=[ \"text\"])\n",
    "   #interpretation=\"default\"\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
